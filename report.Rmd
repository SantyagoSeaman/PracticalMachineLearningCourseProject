---
title: "Practical Machine Learning Course Project"
author: "Alexander Makeev"
date: "11/22/2015"
output:
  html_document:
    highlight: tango
    theme: readable
---

## Executive Summary

This detailed analysis has been performed to fulfill the requirements of the course project for the Practical Machine Learning course on Coursera. Using devices such as Jawbone Up, Nike FuelBand, and Fitbit, it is now possible to collect a large amount of data about personal activity relatively inexpensively. In this project, our goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. 

The main objectives of this project are as follows

   + Predict the manner in which they did the exercise depicted by the `classe` variable.
   + Build a prediction model using different features and cross-validation technique.
   + Calculate the out of sample error.
   + Use the prediction model to predict provided 20 test cases.
<br>

## Data retrieval, clearing and transformation

#### <u>Setting up required environment in R</u>

In the following code segment, we set the required global options and load the required packages in R.
```{r message=FALSE,warning=FALSE}
library(knitr)
library(e1071)
library(xgboost)
library(Matrix)
library(methods)
library(caret)
library(dplyr)
library(Metrics)

set.seed(111)

```
<br>

#### <u>Load data</u>

The links for the training and test data are given below:

* https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
* https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

First of all we load them:

```{r}
if (!file.exists("training.csv")) {
    download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", 
                  destfile = "training.csv")
}
if (!file.exists("testing.csv")) {
    download.file("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", 
                  destfile = "testing.csv")
}

training <- read.csv("training.csv", na.strings=c("NA", "", "#DIV/0!"), stringsAsFactors=FALSE)
testing <- read.csv("testing.csv", na.strings=c("NA", "", "#DIV/0!"), stringsAsFactors=FALSE)
```

<br>

#### <u>Clear data</u>
Whole dataset devided on 1-second windows and a lot of accelerometers have data only once in each window.
There are a lot of columns, where dataset has values only at the first row of 1-second window. All another rows have NA in these columns.
I think, this columns have constant values for whole 1-second window, but anyway in this course project I will simply remove these columns.

```{r}
# for training dataset
columnNACounts <- colSums(is.na(training))        # getting NA counts for all columns
badColumns <- columnNACounts >= 19000             # ignoring columns with majority NA values
training <- training[!badColumns]                 # getting clean data
sum(is.na(training))                              # checking for NA values

# for testing dataset
columnNACounts <- colSums(is.na(testing))
badColumns <- columnNACounts >= 20
testing <- testing[!badColumns]
sum(is.na(testing))
```
As you can see, now we don't have any NA values.


#### <u>Transform data</u>

```{r}
training$classe <- factor(training$classe)
training$user_name <- factor(training$user_name)
training$new_window <- factor(training$new_window)
training$cvtd_timestamp <- NULL

testing$classe <- -1
testing$user_name <- factor(testing$user_name)
testing$new_window <- factor(testing$new_window)
testing$cvtd_timestamp <- NULL
```

<br>

## Build XGBOOST prediction model
#### <u>Create feature list</u>
I decided to remove some features, because using `XGBOOST` and only two predictors `user_name` and `raw_timestamp_part_1` we can predict with perfect accuracy, but I think it will be cheat, not a good prediction model.

```{r}
feature.names <- names(training)
feature.names <- feature.names[-which(feature.names %in% c('X', 'classe'))]
feature.names <- feature.names[-which(feature.names %in% c('user_name', 'raw_timestamp_part_1', 'raw_timestamp_part_2', 'new_window', 'num_window'))]
feature.formula <- formula(paste('classe ~ ', paste(feature.names, collapse = ' + '), sep = ''))
```

#### <u>Create sparse matrixes with data</u>
We'll create training and validation datasets in proportion 1:5
```{r}
dtrain_cv <- training[, c(feature.names, 'classe')]
indexes <- createDataPartition(y = dtrain_cv$classe, p = 0.8, list = FALSE)
dtrain.matrix <- sparse.model.matrix(feature.formula, data = dtrain_cv[indexes, ])
dtrain <- xgb.DMatrix(dtrain.matrix, label = dtrain_cv[indexes, 'classe'])
dvalid <- xgb.DMatrix(sparse.model.matrix(feature.formula, data = dtrain_cv[-indexes, ]),
                      label = dtrain_cv[-indexes, 'classe'])

dtest_cv <- testing[, c(feature.names, 'classe')]
dtest <- sparse.model.matrix(feature.formula, data = dtest_cv)
```

#### <u>Make cross validation</u>
```{r}
n_rounds.cv <- 301
params <- list(booster = "gbtree", objective = "multi:softmax",
               num_class = 6, eval_metric = 'merror',
               max_depth = 6, eta = 0.1,
               colsample_bytree = 1, subsample = 1)

bst.cv <- xgb.cv(params, dtrain, n_rounds.cv, nfold = 5, metrics = {'merror'},
                 print.every.n = 20, prediction = TRUE)

n_rounds.train <- which.min(bst.cv$dt[, test.merror.mean])
n_rounds.train
```
Cross validation gave us required number of `nrounds` for training model.

#### <u>Train the model</u>
```{r}
model <- xgb.train(params = params, data = dtrain, nrounds = n_rounds.train)
```

#### <u>Training dataset accuracy</u>
```{r}
predicted <- factor(predict(model, dtrain), labels = levels(training$classe))
confusionMatrix(predicted, dtrain_cv[indexes, 'classe'])
```

#### <u>Validation dataset accuracy</u>
```{r}
predicted <- factor(predict(model, dvalid), labels = levels(training$classe))
confusionMatrix(predicted, dtrain_cv[-indexes, 'classe'])
```

#### <u>Feature importance</u>
```{r}
feature.importance <- xgb.importance(dimnames(dtrain.matrix)[[2]], model = model)
head(feature.importance)
xgb.plot.importance(feature.importance)
```


## Predict test cases
```{r}
answers <- factor(predict(model, dtest), labels = levels(training$classe))
answers <- as.character(answers)
answers
```

Finally, we write the answers to files
```{r}

pml_write_files = function(x) {
    n = length(x)
    for (i in 1:n) {
        filename = paste0("problem_id_", i, ".txt")
        write.table(x[i], file = filename, quote = FALSE, row.names = FALSE, 
            col.names = FALSE)
    }
}

pml_write_files(answers)
```

## Conclusion
We got accuracy for validation sample near 0.9969 which is 99.7%.
